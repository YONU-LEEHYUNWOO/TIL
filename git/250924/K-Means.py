import gc
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings("ignore")

from sklearn.datasets import load_iris
from sklearn.cluster import KMeans
from sklearn.metrics import confusion_matrix, f1_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA

#loading the iris dataset
data = load_iris()

print(data['DESCR'])

# X's & Y Split
Y = pd.DataFrame(data['target'], columns = ['Target'])
X = pd.DataFrame(data['data'], columns = data['feature_names'])

X.shape

data= pd.concat([X, Y], axis=1)

data.shape

data

#[Clustering ì „ Scaling]
#  - Clusteringì€ Distanceë¥¼ êµ¬í•˜ëŠ” ì‘ì—…ì´ í•„ìš”í•¨
# - Featureë“¤ì˜ Scaleì´ ë‹¤ë¥´ë©´ Distanceë¥¼ êµ¬í•˜ëŠ”ë° ê°€ì¤‘ì¹˜ê°€ ë“¤ì–´ê°€ê²Œ ë¨
#  - ë”°ë¼ì„œ, Distance ê¸°ë°˜ì˜ Clusteringì˜ ê²½ìš° Scalingì´ í•„ìˆ˜


# Scaling
scaler = MinMaxScaler().fit(X)
X_scal = scaler.transform(X)
X_scal = pd.DataFrame(X_scal, columns=X.columns)


pca = PCA(n_components=2).fit(X)
X_PCA = pca.fit_transform(X)
X_EMM = pd.DataFrame(X_PCA, columns=['AXIS1','AXIS2'])
print(">>>> PCA Variance : {}".format(pca.explained_variance_ratio_))




# - K-meansëŠ” Step2ì—ì„œ 'ì´ˆê¸° ì¤‘ì‹¬ì  ì„¤ì •'ì´ë¼ëŠ” ì‘ì—…ì„ í•˜ëŠ”ë°, ì´ˆê¸° ì¤‘ì‹¬ì ì„ ì…‹íŒ…í•˜ëŠ” ê²ƒì— ë”°ë¼ êµ°ì§‘ì˜ Qualityê°€ ë‹¬ë¼ì§
# - ë”°ë¼ì„œ ì—¬ëŸ¬ë²ˆ ì‹œë„í•´ ë³´ëŠ”ê²ƒ 
# - default = 10
# - max_iter : ëª‡ë²ˆ Roundë¥¼ ì§„í–‰í•  ê²ƒ ì¸ì§€
# - Round
[O# - Step 4: ì¤‘ì‹¬ì  ì¬ì„¤ì •
# - Step 5: ë°ì´í„°ë¥¼ êµ°ì§‘ì— ì¬í• ë‹¹
# - ì´ëŸ¬í•œ Roundë¥¼ ìµœëŒ€ ëª‡ë²ˆê¹Œì§€ ëŒê²ƒì¸ê°€?
[I# - default = 300
# - 300ë²ˆ ì•ˆì— ì¤‘ì‹¬ì  ì›€ì§ì„ì´ ë©ˆì¶”ì§€ ì•Šìœ¼ë©´ ê·¸ëƒ¥ STOP





# K-means Modeling
for cluster in list(range(2, 6)):
    Cluster = KMeans(n_clusters=cluster).fit(X_scal)
    labels = Cluster.predict(X_scal)

    # label Add to DataFrame
    data['{} label'.format(cluster)] = labels
    labels = pd.DataFrame(labels, columns=['labels'])
    # Plot Data Setting
    plot_data = pd.concat([X_EMM, labels], axis=1)
    groups = plot_data.groupby('labels')

    mar = ['o', '+', '*', 'D', ',', 'h', '1', '2', '3', '4', 's', '<', '>']
    colo = ['red', 'orange', 'green', 'blue', 'cyan', 'magenta', 'black', 'yellow', 'grey', 'orchid', 'lightpink']

    fig, ax = plt.subplots(figsize=(10,10))
    for j, (name, group) in enumerate(groups):
        ax.plot(group['AXIS1'], 
                group['AXIS2'], 
                marker=mar[j],
                linestyle='',
                label=name,
                c = colo[j],
                ms=10)
        ax.legend(fontsize=12, loc='upper right') # legend position
    plt.title('Scatter Plot', fontsize=20)
    plt.xlabel('AXIS1', fontsize=14)
    plt.ylabel('AXIS2', fontsize=14)
    plt.show()
    print("---------------------------------------------------------------------------------------------------")

    gc.collect()


# Confusion Matrix í™•ì¸
cm = confusion_matrix(data['Target'], data['3 label'])
print(cm)
